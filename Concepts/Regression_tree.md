# Randon Forest
it is version of  Ensemble laenring 
Ensemble learning models work just like a group of diverse experts teaming up to make decisions â€“ think of them as a bunch of friends with different strengths tackling a problem together.

---
some ensemble models include- XGBoost, AdaBoost, LightGBM, Random Forest, Bagging, Voting etc.

---

that combines the output of multiple decision trees to reach a single result

---

when you take a multpile algos or same algos mutiple times which makes stronger than original

---


This randomness introduces variability among individual trees, reducing the risk of overfitting and improving overall prediction performance.

---

Random forests are widely used for classification and regression functions, which are known for their ability to handle complex data, reduce overfitting, and provide reliable forecasts in different environments.


